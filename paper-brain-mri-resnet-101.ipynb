{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:42.821696Z",
     "iopub.status.busy": "2025-04-29T16:16:42.821058Z",
     "iopub.status.idle": "2025-04-29T16:16:56.640112Z",
     "shell.execute_reply": "2025-04-29T16:16:56.639318Z",
     "shell.execute_reply.started": "2025-04-29T16:16:42.821673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from statistics import median_high\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, BatchNormalization, ZeroPadding2D,Activation, AveragePooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.641823Z",
     "iopub.status.busy": "2025-04-29T16:16:56.641401Z",
     "iopub.status.idle": "2025-04-29T16:16:56.645232Z",
     "shell.execute_reply": "2025-04-29T16:16:56.644491Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.641803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_train = \"Datasest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.646086Z",
     "iopub.status.busy": "2025-04-29T16:16:56.645852Z",
     "iopub.status.idle": "2025-04-29T16:16:56.674794Z",
     "shell.execute_reply": "2025-04-29T16:16:56.674163Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.646061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "class_labels = {}\n",
    "for i, classes in enumerate(class_names, start=0):\n",
    "  class_labels[classes] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.676604Z",
     "iopub.status.busy": "2025-04-29T16:16:56.676409Z",
     "iopub.status.idle": "2025-04-29T16:16:56.687689Z",
     "shell.execute_reply": "2025-04-29T16:16:56.687093Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.676588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_size = (130, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.688744Z",
     "iopub.status.busy": "2025-04-29T16:16:56.688523Z",
     "iopub.status.idle": "2025-04-29T16:19:21.674932Z",
     "shell.execute_reply": "2025-04-29T16:19:21.674383Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.688727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#For Training data\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for folder in os.listdir(path_train):\n",
    "    print(\"In folder: {}\".format(folder))\n",
    "    for file in os.listdir(os.path.join(path_train, folder)):\n",
    "        image_path = os.path.join(path_train, folder, file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, image_size)  # Resize the image using image_size\n",
    "        train_data.append(image)\n",
    "        train_labels.append(class_labels[folder])\n",
    "\n",
    "train_data = np.array(train_data, dtype='float32')\n",
    "train_labels = np.array(train_labels, dtype='int32')\n",
    "\n",
    "train_data = train_data / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:21.675864Z",
     "iopub.status.busy": "2025-04-29T16:19:21.675648Z",
     "iopub.status.idle": "2025-04-29T16:19:21.681965Z",
     "shell.execute_reply": "2025-04-29T16:19:21.681343Z",
     "shell.execute_reply.started": "2025-04-29T16:19:21.675848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:21.682670Z",
     "iopub.status.busy": "2025-04-29T16:19:21.682502Z",
     "iopub.status.idle": "2025-04-29T16:19:22.017151Z",
     "shell.execute_reply": "2025-04-29T16:19:22.016408Z",
     "shell.execute_reply.started": "2025-04-29T16:19:21.682657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:22.018144Z",
     "iopub.status.busy": "2025-04-29T16:19:22.017920Z",
     "iopub.status.idle": "2025-04-29T16:19:22.023562Z",
     "shell.execute_reply": "2025-04-29T16:19:22.023023Z",
     "shell.execute_reply.started": "2025-04-29T16:19:22.018126Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "labels_encoded = to_categorical(labels_encoded)\n",
    "\n",
    "# Print the mapping of labels to their encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:22.024669Z",
     "iopub.status.busy": "2025-04-29T16:19:22.024377Z",
     "iopub.status.idle": "2025-04-29T16:19:22.605939Z",
     "shell.execute_reply": "2025-04-29T16:19:22.605154Z",
     "shell.execute_reply.started": "2025-04-29T16:19:22.024630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Convert to numpy arrays and reshape\n",
    "X_train = np.array(X_train).reshape(-1, 130, 130, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 130, 130, 1)\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:22.608451Z",
     "iopub.status.busy": "2025-04-29T16:19:22.608248Z",
     "iopub.status.idle": "2025-04-29T16:19:24.087486Z",
     "shell.execute_reply": "2025-04-29T16:19:24.086885Z",
     "shell.execute_reply.started": "2025-04-29T16:19:22.608435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Resize images before converting to numpy arrays\n",
    "X_train_resized = np.array([cv2.resize(img, (156, 156)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (156, 156)) for img in X_test])\n",
    "\n",
    "# Reshape\n",
    "X_train_resized = X_train_resized.reshape(-1, 156, 156, 1)\n",
    "X_test_resized = X_test_resized.reshape(-1, 156, 156, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:24.088357Z",
     "iopub.status.busy": "2025-04-29T16:19:24.088180Z",
     "iopub.status.idle": "2025-04-29T16:19:24.093756Z",
     "shell.execute_reply": "2025-04-29T16:19:24.092972Z",
     "shell.execute_reply.started": "2025-04-29T16:19:24.088343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"y_train classes:\", np.unique(y_train))\n",
    "print(\"y_test classes:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:24.094890Z",
     "iopub.status.busy": "2025-04-29T16:19:24.094602Z",
     "iopub.status.idle": "2025-04-29T16:19:24.108441Z",
     "shell.execute_reply": "2025-04-29T16:19:24.107895Z",
     "shell.execute_reply.started": "2025-04-29T16:19:24.094861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train_categorical = keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Verify the shape (should be (n_samples, 4) for both)\n",
    "print(\"y_train_categorical shape:\", y_train_categorical.shape)\n",
    "print(\"y_test_categorical shape:\", y_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T15:33:16.519639Z",
     "iopub.status.busy": "2025-04-29T15:33:16.519144Z",
     "iopub.status.idle": "2025-04-29T15:33:16.532243Z",
     "shell.execute_reply": "2025-04-29T15:33:16.531445Z",
     "shell.execute_reply.started": "2025-04-29T15:33:16.519621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add, Flatten\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:22:32.299257Z",
     "iopub.status.busy": "2025-04-29T16:22:32.298663Z",
     "iopub.status.idle": "2025-04-29T16:22:34.440291Z",
     "shell.execute_reply": "2025-04-29T16:22:34.439488Z",
     "shell.execute_reply.started": "2025-04-29T16:22:32.299235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Saving the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First layer\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third layer\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Shortcut path\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value here, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def ResNet101(input_shape=(130, 130, 1), classes=4):\n",
    "    \"\"\"\n",
    "    Implementation of the ResNet101 architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*3 -> CONVBLOCK -> IDBLOCK*4\n",
    "    -> CONVBLOCK -> IDBLOCK*23 -> CONVBLOCK -> IDBLOCK*3 -> AVGPOOL -> TOPLAYER\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='d')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='e')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    for i in range(1, 24):  # 23 identity blocks\n",
    "        X = identity_block(X, 3, [256, 256, 1024], stage=4, block=chr(97 + i))  # 'b' to 'x'\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='d')\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet101')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_ResNet101 = ResNet101(input_shape=(130, 130, 1), classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:22:34.441700Z",
     "iopub.status.busy": "2025-04-29T16:22:34.441423Z",
     "iopub.status.idle": "2025-04-29T16:22:34.449659Z",
     "shell.execute_reply": "2025-04-29T16:22:34.449149Z",
     "shell.execute_reply.started": "2025-04-29T16:22:34.441675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_ResNet101.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:22:36.228746Z",
     "iopub.status.busy": "2025-04-29T16:22:36.228459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the path where the model with the best parameters will be saved\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create a callback that saves the model with the best validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',  # Save when val_accuracy is maximized\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback with patience=5\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=5,  # Stop training if no improvement after 10 epochs\n",
    "    mode='max',  # Check for maximization of val_accuracy\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint and early stopping callbacks\n",
    "history1 = model_ResNet101.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-121 With EfficientNet Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T07:06:55.188867Z",
     "iopub.status.busy": "2025-04-29T07:06:55.188103Z",
     "iopub.status.idle": "2025-04-29T07:06:56.726982Z",
     "shell.execute_reply": "2025-04-29T07:06:56.726192Z",
     "shell.execute_reply.started": "2025-04-29T07:06:55.188838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base\t X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), strides=(s, s), name=conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "def ResNet101_Scaled(input_shape=(156, 156, 1), classes=4):\n",
    "    \"\"\"\n",
    "    ResNet101 with scaled parameters but original layer counts.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(77, (7, 7), strides=(2, 2), name='conv1')(X)  # 64 * 1.2 = 77\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[77, 77, 307], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [77, 77, 307], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [77, 77, 307], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[154, 154, 614], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [154, 154, 614], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [154, 154, 614], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [154, 154, 614], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[307, 307, 1229], stage=4, block='a', s=2)\n",
    "    for i in range(1, 23):  # 22 identity blocks, 'b' to 'w'\n",
    "        X = identity_block(X, 3, [307, 307, 1229], stage=4, block=chr(97 + i))\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[614, 614, 2458], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [614, 614, 2458], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [614, 614, 2458], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D((2, 2), name=\"avg_pool\")(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(2458, activation='relu', name='fc_dense')(X)  # 2048 * 1.2 = 2458\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc_output')(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet101_Scaled')\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model_ResNet101_scaled = ResNet101_Scaled(input_shape=(156, 156, 1), classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T07:06:56.728704Z",
     "iopub.status.busy": "2025-04-29T07:06:56.728402Z",
     "iopub.status.idle": "2025-04-29T07:06:56.737738Z",
     "shell.execute_reply": "2025-04-29T07:06:56.737091Z",
     "shell.execute_reply.started": "2025-04-29T07:06:56.728678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_ResNet101_scaled.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T07:06:56.738669Z",
     "iopub.status.busy": "2025-04-29T07:06:56.738400Z",
     "iopub.status.idle": "2025-04-29T09:28:34.994541Z",
     "shell.execute_reply": "2025-04-29T09:28:34.993947Z",
     "shell.execute_reply.started": "2025-04-29T07:06:56.738627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the path where the model with the best parameters will be saved\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create a callback that saves the model with the best validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',  # Save when val_accuracy is maximized\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback with patience=5\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=5,  # Stop training if no improvement after 10 epochs\n",
    "    mode='max',  # Check for maximization of val_accuracy\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint and early stopping callbacks\n",
    "history2 = model_ResNet101_scaled.fit(X_train_resized, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:13:15.444177Z",
     "iopub.status.busy": "2025-04-29T16:13:15.443963Z",
     "iopub.status.idle": "2025-04-29T16:13:15.812828Z",
     "shell.execute_reply": "2025-04-29T16:13:15.811989Z",
     "shell.execute_reply.started": "2025-04-29T16:13:15.444153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history1.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history1.history['val_accuracy'], label='Val Accuracy', linestyle='--')\n",
    "plt.title('ResNet-101 Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history1.history['loss'], label='Train Loss')\n",
    "plt.plot(history1.history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.title('ResNet-101 Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T09:28:42.867381Z",
     "iopub.status.busy": "2025-04-29T09:28:42.866849Z",
     "iopub.status.idle": "2025-04-29T09:28:43.222679Z",
     "shell.execute_reply": "2025-04-29T09:28:43.222019Z",
     "shell.execute_reply.started": "2025-04-29T09:28:42.867351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history2.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history2.history['val_accuracy'], label='Val Accuracy', linestyle='--')\n",
    "plt.title('ResNet-101 Scaled Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history2.history['loss'], label='Train Loss')\n",
    "plt.plot(history2.history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.title('ResNet-101 Scaled Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:13:15.814017Z",
     "iopub.status.busy": "2025-04-29T16:13:15.813745Z",
     "iopub.status.idle": "2025-04-29T16:13:16.176827Z",
     "shell.execute_reply": "2025-04-29T16:13:16.175978Z",
     "shell.execute_reply.started": "2025-04-29T16:13:15.813996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Function to calculate specificity and sensitivity for multi-class\n",
    "def specificity_score_multiclass(conf_matrix):\n",
    "    specificity_per_class = []\n",
    "    sensitivity_per_class = []\n",
    "    \n",
    "    for i in range(conf_matrix.shape[0]):  # Loop through each class\n",
    "        tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "        fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - conf_matrix[i, i]\n",
    "        tp = conf_matrix[i, i]\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        specificity_per_class.append(specificity)\n",
    "        sensitivity_per_class.append(sensitivity)\n",
    "    \n",
    "    return specificity_per_class, sensitivity_per_class\n",
    "\n",
    "# Function to print model metrics and confusion matrix\n",
    "def print_model_metrics(y_true, y_pred, model_name, class_names):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Compute specificity and sensitivity for each class\n",
    "    specificity, sensitivity = specificity_score_multiclass(conf_matrix)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nMetrics for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name}: Specificity: {specificity[i]:.4f}, Sensitivity: {sensitivity[i]:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Function to plot one image per class with predicted and true labels\n",
    "def plot_sample_images_per_class(X, y_true, y_pred, class_names):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    shown_classes = set()\n",
    "    class_indices = {}\n",
    "\n",
    "    # Find one index per class\n",
    "    for idx, label in enumerate(y_true):\n",
    "        if label not in shown_classes:\n",
    "            class_indices[label] = idx\n",
    "            shown_classes.add(label)\n",
    "        if len(shown_classes) == len(class_names):\n",
    "            break\n",
    "\n",
    "    for i, (label, idx) in enumerate(class_indices.items()):\n",
    "        image = X[idx]\n",
    "        if image.shape[-1] == 1:  # Grayscale\n",
    "            image = image.squeeze()\n",
    "        plt.subplot(1, len(class_names), i + 1)\n",
    "        plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"True: {class_names[y_true[idx]]}\\nPred: {class_names[y_pred[idx]]}\")\n",
    "\n",
    "    plt.suptitle(\"Sample Image Per Class with Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define your actual class names\n",
    "class_names = [\"Pituitary\", \"No Tumor\", \"Meningioma\", \"Glioma\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:13:16.178270Z",
     "iopub.status.busy": "2025-04-29T16:13:16.177742Z",
     "iopub.status.idle": "2025-04-29T16:13:44.688578Z",
     "shell.execute_reply": "2025-04-29T16:13:44.687659Z",
     "shell.execute_reply.started": "2025-04-29T16:13:16.178250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get predictions from your trained model\n",
    "y_pred1 = np.argmax(model_ResNet101.predict(X_test), axis=1)\n",
    "y_true1 = y_test  # Assuming it's label-encoded already\n",
    "\n",
    "# Show metrics and plots\n",
    "print_model_metrics(y_true1, y_pred1, 'ResNet-101', class_names)\n",
    "plot_sample_images_per_class(X_test, y_true1, y_pred1, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T09:29:14.800149Z",
     "iopub.status.busy": "2025-04-29T09:29:14.799957Z",
     "iopub.status.idle": "2025-04-29T09:30:09.446083Z",
     "shell.execute_reply": "2025-04-29T09:30:09.445355Z",
     "shell.execute_reply.started": "2025-04-29T09:29:14.800134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get predictions from your trained model\n",
    "y_pred1 = np.argmax(model_ResNet101_scaled_dense.predict(X_test_resized), axis=1)\n",
    "y_true1 = y_test  # Assuming it's label-encoded already\n",
    "\n",
    "# Show metrics and plots\n",
    "print_model_metrics(y_true1, y_pred1, 'ResNet-101', class_names)\n",
    "plot_sample_images_per_class(X_test_resized, y_true1, y_pred1, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3531266,
     "sourceId": 6568541,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
