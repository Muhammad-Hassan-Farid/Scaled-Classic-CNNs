{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:42.821696Z",
     "iopub.status.busy": "2025-04-29T16:16:42.821058Z",
     "iopub.status.idle": "2025-04-29T16:16:56.640112Z",
     "shell.execute_reply": "2025-04-29T16:16:56.639318Z",
     "shell.execute_reply.started": "2025-04-29T16:16:42.821673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from statistics import median_high\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, BatchNormalization, ZeroPadding2D,Activation, AveragePooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.641823Z",
     "iopub.status.busy": "2025-04-29T16:16:56.641401Z",
     "iopub.status.idle": "2025-04-29T16:16:56.645232Z",
     "shell.execute_reply": "2025-04-29T16:16:56.644491Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.641803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_train = \"/kaggle/input/brainmri/Datasest Merged 1/Datasest Merged 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.646086Z",
     "iopub.status.busy": "2025-04-29T16:16:56.645852Z",
     "iopub.status.idle": "2025-04-29T16:16:56.674794Z",
     "shell.execute_reply": "2025-04-29T16:16:56.674163Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.646061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "class_labels = {}\n",
    "for i, classes in enumerate(class_names, start=0):\n",
    "  class_labels[classes] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.676604Z",
     "iopub.status.busy": "2025-04-29T16:16:56.676409Z",
     "iopub.status.idle": "2025-04-29T16:16:56.687689Z",
     "shell.execute_reply": "2025-04-29T16:16:56.687093Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.676588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_size = (130, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:16:56.688744Z",
     "iopub.status.busy": "2025-04-29T16:16:56.688523Z",
     "iopub.status.idle": "2025-04-29T16:19:21.674932Z",
     "shell.execute_reply": "2025-04-29T16:19:21.674383Z",
     "shell.execute_reply.started": "2025-04-29T16:16:56.688727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#For Training data\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for folder in os.listdir(path_train):\n",
    "    print(\"In folder: {}\".format(folder))\n",
    "    for file in os.listdir(os.path.join(path_train, folder)):\n",
    "        image_path = os.path.join(path_train, folder, file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, image_size)  # Resize the image using image_size\n",
    "        train_data.append(image)\n",
    "        train_labels.append(class_labels[folder])\n",
    "\n",
    "train_data = np.array(train_data, dtype='float32')\n",
    "train_labels = np.array(train_labels, dtype='int32')\n",
    "\n",
    "train_data = train_data / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:21.675864Z",
     "iopub.status.busy": "2025-04-29T16:19:21.675648Z",
     "iopub.status.idle": "2025-04-29T16:19:21.681965Z",
     "shell.execute_reply": "2025-04-29T16:19:21.681343Z",
     "shell.execute_reply.started": "2025-04-29T16:19:21.675848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:21.682670Z",
     "iopub.status.busy": "2025-04-29T16:19:21.682502Z",
     "iopub.status.idle": "2025-04-29T16:19:22.017151Z",
     "shell.execute_reply": "2025-04-29T16:19:22.016408Z",
     "shell.execute_reply.started": "2025-04-29T16:19:21.682657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:22.018144Z",
     "iopub.status.busy": "2025-04-29T16:19:22.017920Z",
     "iopub.status.idle": "2025-04-29T16:19:22.023562Z",
     "shell.execute_reply": "2025-04-29T16:19:22.023023Z",
     "shell.execute_reply.started": "2025-04-29T16:19:22.018126Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "labels_encoded = to_categorical(labels_encoded)\n",
    "\n",
    "# Print the mapping of labels to their encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:22.024669Z",
     "iopub.status.busy": "2025-04-29T16:19:22.024377Z",
     "iopub.status.idle": "2025-04-29T16:19:22.605939Z",
     "shell.execute_reply": "2025-04-29T16:19:22.605154Z",
     "shell.execute_reply.started": "2025-04-29T16:19:22.024630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Convert to numpy arrays and reshape\n",
    "X_train = np.array(X_train).reshape(-1, 130, 130, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 130, 130, 1)\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:22.608451Z",
     "iopub.status.busy": "2025-04-29T16:19:22.608248Z",
     "iopub.status.idle": "2025-04-29T16:19:24.087486Z",
     "shell.execute_reply": "2025-04-29T16:19:24.086885Z",
     "shell.execute_reply.started": "2025-04-29T16:19:22.608435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Resize images before converting to numpy arrays\n",
    "X_train_resized = np.array([cv2.resize(img, (156, 156)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (156, 156)) for img in X_test])\n",
    "\n",
    "# Reshape\n",
    "X_train_resized = X_train_resized.reshape(-1, 156, 156, 1)\n",
    "X_test_resized = X_test_resized.reshape(-1, 156, 156, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:24.088357Z",
     "iopub.status.busy": "2025-04-29T16:19:24.088180Z",
     "iopub.status.idle": "2025-04-29T16:19:24.093756Z",
     "shell.execute_reply": "2025-04-29T16:19:24.092972Z",
     "shell.execute_reply.started": "2025-04-29T16:19:24.088343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"y_train classes:\", np.unique(y_train))\n",
    "print(\"y_test classes:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:19:24.094890Z",
     "iopub.status.busy": "2025-04-29T16:19:24.094602Z",
     "iopub.status.idle": "2025-04-29T16:19:24.108441Z",
     "shell.execute_reply": "2025-04-29T16:19:24.107895Z",
     "shell.execute_reply.started": "2025-04-29T16:19:24.094861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train_categorical = keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Verify the shape (should be (n_samples, 4) for both)\n",
    "print(\"y_train_categorical shape:\", y_train_categorical.shape)\n",
    "print(\"y_test_categorical shape:\", y_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T17:55:43.352079Z",
     "iopub.status.busy": "2025-04-29T17:55:43.351776Z",
     "iopub.status.idle": "2025-04-29T17:55:45.437685Z",
     "shell.execute_reply": "2025-04-29T17:55:45.437019Z",
     "shell.execute_reply.started": "2025-04-29T17:55:43.352023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation, concatenate,\n",
    "                                     AveragePooling2D, GlobalAveragePooling2D, Dense, MaxPooling2D, ZeroPadding2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(x)\n",
    "    x1 = Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(x1)\n",
    "    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x1)\n",
    "    x1 = Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(x1)\n",
    "    x = concatenate([x, x1], axis=bn_axis, name=name + '_concat')\n",
    "    return x\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')(x)\n",
    "    x = Activation('relu', name=name + '_relu')(x)\n",
    "    x = Conv2D(int(tf.keras.backend.int_shape(x)[bn_axis] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
    "    x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "def DenseNet169(input_shape=(130, 130, 1), classes=4):\n",
    "    \"\"\"Instantiates the DenseNet-169 architecture.\"\"\"\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    \n",
    "    x = ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = Conv2D(64, 7, strides=2, use_bias=False, name='conv1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "    \n",
    "    x = dense_block(x, 6, name='conv2')   # 6 conv blocks\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, 12, name='conv3')  # 12 conv blocks\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, 32, name='conv4')  # 24 -> 32 conv blocks\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, 32, name='conv5')  # 16 -> 32 conv blocks\n",
    "    \n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = Activation('relu', name='relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(classes, activation='softmax', name='fc')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(img_input, x, name='densenet169')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "DenseNet169_model = DenseNet169(input_shape=(130, 130, 1), classes=4)\n",
    "\n",
    "# Optional: Display model summary\n",
    "DenseNet169_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T17:55:45.438971Z",
     "iopub.status.busy": "2025-04-29T17:55:45.438766Z",
     "iopub.status.idle": "2025-04-29T17:55:45.447942Z",
     "shell.execute_reply": "2025-04-29T17:55:45.447191Z",
     "shell.execute_reply.started": "2025-04-29T17:55:45.438956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DenseNet169_model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T17:55:45.448896Z",
     "iopub.status.busy": "2025-04-29T17:55:45.448689Z",
     "iopub.status.idle": "2025-04-29T18:15:51.256184Z",
     "shell.execute_reply": "2025-04-29T18:15:51.255559Z",
     "shell.execute_reply.started": "2025-04-29T17:55:45.448874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the path where the model with the best parameters will be saved\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create a callback that saves the model with the best validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',  # Save when val_accuracy is maximized\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback with patience=5\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=5,  # Stop training if no improvement after 10 epochs\n",
    "    mode='max',  # Check for maximization of val_accuracy\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint and early stopping callbacks\n",
    "history1 = DenseNet169_model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-169 With EfficientNet Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:18:23.540861Z",
     "iopub.status.busy": "2025-04-29T18:18:23.540184Z",
     "iopub.status.idle": "2025-04-29T18:18:25.769962Z",
     "shell.execute_reply": "2025-04-29T18:18:25.769420Z",
     "shell.execute_reply.started": "2025-04-29T18:18:23.540840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation, concatenate,\n",
    "                                     AveragePooling2D, GlobalAveragePooling2D, Dense, MaxPooling2D, ZeroPadding2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(x)\n",
    "    x1 = Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = Conv2D(4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(x1)\n",
    "    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x1)\n",
    "    x1 = Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(x1)\n",
    "    x = concatenate([x, x1], axis=bn_axis, name=name + '_concat')\n",
    "    return x\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\"\"\"\n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')(x)\n",
    "    x = Activation('relu', name=name + '_relu')(x)\n",
    "    x = Conv2D(int(tf.keras.backend.int_shape(x)[bn_axis] * reduction), 1, use_bias=False, name=name + '_conv')(x)\n",
    "    x = AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 38, name=name + '_block' + str(i + 1))  # Growth rate: 32 -> 38\n",
    "    return x\n",
    "\n",
    "def DenseNet169_Scaled(input_shape=(156, 156, 1), classes=4):\n",
    "    \"\"\"DenseNet-169 with scaled parameters but original layer counts.\"\"\"\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    bn_axis = 3 if K.image_data_format() == 'channels_last' else 1\n",
    "    \n",
    "    x = ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = Conv2D(77, 7, strides=2, use_bias=False, name='conv1_conv')(x)  # 64 * 1.2 = 77\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "    \n",
    "    # Original DenseNet-169 block counts\n",
    "    x = dense_block(x, 6, name='conv2')   # 6 blocks\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, 12, name='conv3')  # 12 blocks\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, 32, name='conv4')  # 32 blocks\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, 32, name='conv5')  # 32 blocks\n",
    "    \n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = Activation('relu', name='relu')(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(2458, activation='relu', name='fc_dense')(x)  # 2048 * 1.2 = 2458\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = Dense(classes, activation='softmax', name='fc_output')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(img_input, x, name='densenet169_scaled')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model_DenseNet169_scaled = DenseNet169_Scaled(input_shape=(156, 156, 1), classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:18:25.771331Z",
     "iopub.status.busy": "2025-04-29T18:18:25.771090Z",
     "iopub.status.idle": "2025-04-29T18:18:25.779893Z",
     "shell.execute_reply": "2025-04-29T18:18:25.779204Z",
     "shell.execute_reply.started": "2025-04-29T18:18:25.771304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_DenseNet169_scaled.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:18:25.780891Z",
     "iopub.status.busy": "2025-04-29T18:18:25.780682Z",
     "iopub.status.idle": "2025-04-29T18:50:32.465711Z",
     "shell.execute_reply": "2025-04-29T18:50:32.464900Z",
     "shell.execute_reply.started": "2025-04-29T18:18:25.780867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the path where the model with the best parameters will be saved\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create a callback that saves the model with the best validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',  # Save when val_accuracy is maximized\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback with patience=5\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=5,  # Stop training if no improvement after 10 epochs\n",
    "    mode='max',  # Check for maximization of val_accuracy\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint and early stopping callbacks\n",
    "history2 = model_DenseNet169_scaled.fit(X_train_resized, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:50:32.467478Z",
     "iopub.status.busy": "2025-04-29T18:50:32.467263Z",
     "iopub.status.idle": "2025-04-29T18:50:32.779063Z",
     "shell.execute_reply": "2025-04-29T18:50:32.778318Z",
     "shell.execute_reply.started": "2025-04-29T18:50:32.467461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history1.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history1.history['val_accuracy'], label='Val Accuracy', linestyle='--')\n",
    "plt.title('DenseNet-169 Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history1.history['loss'], label='Train Loss')\n",
    "plt.plot(history1.history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.title('DenseNet-169 Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:50:32.779838Z",
     "iopub.status.busy": "2025-04-29T18:50:32.779666Z",
     "iopub.status.idle": "2025-04-29T18:50:33.081654Z",
     "shell.execute_reply": "2025-04-29T18:50:33.080456Z",
     "shell.execute_reply.started": "2025-04-29T18:50:32.779825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history2.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history2.history['val_accuracy'], label='Val Accuracy', linestyle='--')\n",
    "plt.title('DenseNet-169 Scaled Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history2.history['loss'], label='Train Loss')\n",
    "plt.plot(history2.history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.title('DenseNet-169 Scaled Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:50:33.083069Z",
     "iopub.status.busy": "2025-04-29T18:50:33.082746Z",
     "iopub.status.idle": "2025-04-29T18:50:33.095981Z",
     "shell.execute_reply": "2025-04-29T18:50:33.095088Z",
     "shell.execute_reply.started": "2025-04-29T18:50:33.083042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Function to calculate specificity and sensitivity for multi-class\n",
    "def specificity_score_multiclass(conf_matrix):\n",
    "    specificity_per_class = []\n",
    "    sensitivity_per_class = []\n",
    "    \n",
    "    for i in range(conf_matrix.shape[0]):  # Loop through each class\n",
    "        tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "        fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - conf_matrix[i, i]\n",
    "        tp = conf_matrix[i, i]\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        specificity_per_class.append(specificity)\n",
    "        sensitivity_per_class.append(sensitivity)\n",
    "    \n",
    "    return specificity_per_class, sensitivity_per_class\n",
    "\n",
    "# Function to print model metrics and confusion matrix\n",
    "def print_model_metrics(y_true, y_pred, model_name, class_names):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Compute specificity and sensitivity for each class\n",
    "    specificity, sensitivity = specificity_score_multiclass(conf_matrix)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nMetrics for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name}: Specificity: {specificity[i]:.4f}, Sensitivity: {sensitivity[i]:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Function to plot one image per class with predicted and true labels\n",
    "def plot_sample_images_per_class(X, y_true, y_pred, class_names):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    shown_classes = set()\n",
    "    class_indices = {}\n",
    "\n",
    "    # Find one index per class\n",
    "    for idx, label in enumerate(y_true):\n",
    "        if label not in shown_classes:\n",
    "            class_indices[label] = idx\n",
    "            shown_classes.add(label)\n",
    "        if len(shown_classes) == len(class_names):\n",
    "            break\n",
    "\n",
    "    for i, (label, idx) in enumerate(class_indices.items()):\n",
    "        image = X[idx]\n",
    "        if image.shape[-1] == 1:  # Grayscale\n",
    "            image = image.squeeze()\n",
    "        plt.subplot(1, len(class_names), i + 1)\n",
    "        plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"True: {class_names[y_true[idx]]}\\nPred: {class_names[y_pred[idx]]}\")\n",
    "\n",
    "    plt.suptitle(\"Sample Image Per Class with Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define your actual class names\n",
    "class_names = [\"Pituitary\", \"No Tumor\", \"Meningioma\", \"Glioma\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:50:33.097132Z",
     "iopub.status.busy": "2025-04-29T18:50:33.096816Z",
     "iopub.status.idle": "2025-04-29T18:51:10.272993Z",
     "shell.execute_reply": "2025-04-29T18:51:10.272345Z",
     "shell.execute_reply.started": "2025-04-29T18:50:33.097105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get predictions from your trained model\n",
    "y_pred1 = np.argmax(DenseNet169_model.predict(X_test), axis=1)\n",
    "y_true1 = y_test  # Assuming it's label-encoded already\n",
    "\n",
    "# Show metrics and plots\n",
    "print_model_metrics(y_true1, y_pred1, 'DenseNet-169', class_names)\n",
    "plot_sample_images_per_class(X_test, y_true1, y_pred1, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:51:10.274748Z",
     "iopub.status.busy": "2025-04-29T18:51:10.274525Z",
     "iopub.status.idle": "2025-04-29T18:52:20.319613Z",
     "shell.execute_reply": "2025-04-29T18:52:20.318824Z",
     "shell.execute_reply.started": "2025-04-29T18:51:10.274730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get predictions from your trained model\n",
    "y_pred1 = np.argmax(model_DenseNet169_scaled.predict(X_test_resized), axis=1)\n",
    "y_true1 = y_test  # Assuming it's label-encoded already\n",
    "\n",
    "# Show metrics and plots\n",
    "print_model_metrics(y_true1, y_pred1, 'DenseNet-169 Scaled', class_names)\n",
    "plot_sample_images_per_class(X_test_resized, y_true1, y_pred1, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3531266,
     "sourceId": 6568541,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
