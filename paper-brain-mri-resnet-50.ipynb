{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:22:39.294411Z",
     "iopub.status.busy": "2025-04-28T04:22:39.294156Z",
     "iopub.status.idle": "2025-04-28T04:22:53.205554Z",
     "shell.execute_reply": "2025-04-28T04:22:53.204992Z",
     "shell.execute_reply.started": "2025-04-28T04:22:39.294390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from statistics import median_high\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, BatchNormalization, ZeroPadding2D,Activation, AveragePooling2D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:22:53.207555Z",
     "iopub.status.busy": "2025-04-28T04:22:53.206861Z",
     "iopub.status.idle": "2025-04-28T04:22:53.210601Z",
     "shell.execute_reply": "2025-04-28T04:22:53.210042Z",
     "shell.execute_reply.started": "2025-04-28T04:22:53.207534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_train = \"/kaggle/input/brainmri/Datasest Merged 1/Datasest Merged 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:22:53.211743Z",
     "iopub.status.busy": "2025-04-28T04:22:53.211456Z",
     "iopub.status.idle": "2025-04-28T04:22:53.393096Z",
     "shell.execute_reply": "2025-04-28T04:22:53.392395Z",
     "shell.execute_reply.started": "2025-04-28T04:22:53.211700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "class_labels = {}\n",
    "for i, classes in enumerate(class_names, start=0):\n",
    "  class_labels[classes] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:22:53.394836Z",
     "iopub.status.busy": "2025-04-28T04:22:53.394623Z",
     "iopub.status.idle": "2025-04-28T04:22:53.403262Z",
     "shell.execute_reply": "2025-04-28T04:22:53.402650Z",
     "shell.execute_reply.started": "2025-04-28T04:22:53.394819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_size = (130, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:22:53.404097Z",
     "iopub.status.busy": "2025-04-28T04:22:53.403875Z",
     "iopub.status.idle": "2025-04-28T04:25:15.818602Z",
     "shell.execute_reply": "2025-04-28T04:25:15.818033Z",
     "shell.execute_reply.started": "2025-04-28T04:22:53.404080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#For Training data\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for folder in os.listdir(path_train):\n",
    "    print(\"In folder: {}\".format(folder))\n",
    "    for file in os.listdir(os.path.join(path_train, folder)):\n",
    "        image_path = os.path.join(path_train, folder, file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, image_size)  # Resize the image using image_size\n",
    "        train_data.append(image)\n",
    "        train_labels.append(class_labels[folder])\n",
    "\n",
    "train_data = np.array(train_data, dtype='float32')\n",
    "train_labels = np.array(train_labels, dtype='int32')\n",
    "\n",
    "train_data = train_data / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:25:15.819502Z",
     "iopub.status.busy": "2025-04-28T04:25:15.819318Z",
     "iopub.status.idle": "2025-04-28T04:25:15.825362Z",
     "shell.execute_reply": "2025-04-28T04:25:15.824852Z",
     "shell.execute_reply.started": "2025-04-28T04:25:15.819488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:25:15.826270Z",
     "iopub.status.busy": "2025-04-28T04:25:15.826067Z",
     "iopub.status.idle": "2025-04-28T04:25:16.141917Z",
     "shell.execute_reply": "2025-04-28T04:25:16.141256Z",
     "shell.execute_reply.started": "2025-04-28T04:25:15.826255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:25:16.142757Z",
     "iopub.status.busy": "2025-04-28T04:25:16.142547Z",
     "iopub.status.idle": "2025-04-28T04:25:16.148447Z",
     "shell.execute_reply": "2025-04-28T04:25:16.147790Z",
     "shell.execute_reply.started": "2025-04-28T04:25:16.142733Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "labels_encoded = to_categorical(labels_encoded)\n",
    "\n",
    "# Print the mapping of labels to their encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:25:16.149870Z",
     "iopub.status.busy": "2025-04-28T04:25:16.149255Z",
     "iopub.status.idle": "2025-04-28T04:25:16.725561Z",
     "shell.execute_reply": "2025-04-28T04:25:16.724755Z",
     "shell.execute_reply.started": "2025-04-28T04:25:16.149844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Convert to numpy arrays and reshape\n",
    "X_train = np.array(X_train).reshape(-1, 130, 130, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 130, 130, 1)\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T04:25:16.727687Z",
     "iopub.status.busy": "2025-04-28T04:25:16.727283Z",
     "iopub.status.idle": "2025-04-28T04:25:18.170516Z",
     "shell.execute_reply": "2025-04-28T04:25:18.169768Z",
     "shell.execute_reply.started": "2025-04-28T04:25:16.727668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Resize images before converting to numpy arrays\n",
    "X_train_resized = np.array([cv2.resize(img, (156, 156)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (156, 156)) for img in X_test])\n",
    "\n",
    "# Reshape\n",
    "X_train_resized = X_train_resized.reshape(-1, 156, 156, 1)\n",
    "X_test_resized = X_test_resized.reshape(-1, 156, 156, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:14:39.437544Z",
     "iopub.status.busy": "2025-04-28T06:14:39.437269Z",
     "iopub.status.idle": "2025-04-28T06:14:39.442872Z",
     "shell.execute_reply": "2025-04-28T06:14:39.442182Z",
     "shell.execute_reply.started": "2025-04-28T06:14:39.437522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"y_train classes:\", np.unique(y_train))\n",
    "print(\"y_test classes:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:15:41.294059Z",
     "iopub.status.busy": "2025-04-28T06:15:41.293817Z",
     "iopub.status.idle": "2025-04-28T06:15:41.299458Z",
     "shell.execute_reply": "2025-04-28T06:15:41.298840Z",
     "shell.execute_reply.started": "2025-04-28T06:15:41.294043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train_categorical = keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Verify the shape (should be (n_samples, 4) for both)\n",
    "print(\"y_train_categorical shape:\", y_train_categorical.shape)\n",
    "print(\"y_test_categorical shape:\", y_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:15:45.713743Z",
     "iopub.status.busy": "2025-04-28T06:15:45.713213Z",
     "iopub.status.idle": "2025-04-28T06:15:45.717122Z",
     "shell.execute_reply": "2025-04-28T06:15:45.716443Z",
     "shell.execute_reply.started": "2025-04-28T06:15:45.713693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add, Flatten\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:15:47.323878Z",
     "iopub.status.busy": "2025-04-28T06:15:47.323190Z",
     "iopub.status.idle": "2025-04-28T06:15:47.847111Z",
     "shell.execute_reply": "2025-04-28T06:15:47.846322Z",
     "shell.execute_reply.started": "2025-04-28T06:15:47.323852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Saving the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First layer\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third layer\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Shortcut path\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value here, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "def ResNet50(input_shape=(130, 130, 1), classes=4):\n",
    "    \"\"\"\n",
    "    Implementation of the ResNet50 architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(4, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "model_ResNet50 = ResNet50(input_shape=(130, 130, 1), classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:15:52.176278Z",
     "iopub.status.busy": "2025-04-28T06:15:52.176022Z",
     "iopub.status.idle": "2025-04-28T06:15:52.184689Z",
     "shell.execute_reply": "2025-04-28T06:15:52.183971Z",
     "shell.execute_reply.started": "2025-04-28T06:15:52.176259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_ResNet50.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:15:53.161001Z",
     "iopub.status.busy": "2025-04-28T06:15:53.160342Z",
     "iopub.status.idle": "2025-04-28T06:30:25.647634Z",
     "shell.execute_reply": "2025-04-28T06:30:25.646897Z",
     "shell.execute_reply.started": "2025-04-28T06:15:53.160977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the path where the model with the best parameters will be saved\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create a callback that saves the model with the best validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',  # Save when val_accuracy is maximized\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback with patience=5\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=5,  # Stop training if no improvement after 10 epochs\n",
    "    mode='max',  # Check for maximization of val_accuracy\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint and early stopping callbacks\n",
    "history1 = model_ResNet50.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=50,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-50 With EfficientNet Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:37:27.009180Z",
     "iopub.status.busy": "2025-04-28T06:37:27.008589Z",
     "iopub.status.idle": "2025-04-28T06:37:27.704802Z",
     "shell.execute_reply": "2025-04-28T06:37:27.703858Z",
     "shell.execute_reply.started": "2025-04-28T06:37:27.009154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, Flatten, Dense, Add, ZeroPadding2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), strides=(s, s), name=conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "\n",
    "def ResNet50_Scaled(input_shape=(156, 156, 1), classes=4):\n",
    "    \"\"\"\n",
    "    ResNet50 with scaled parameters but original layer counts.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(77, (7, 7), strides=(2, 2), name='conv1')(X)  # 64 * 1.2 = 77\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[77, 77, 307], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [77, 77, 307], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [77, 77, 307], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[154, 154, 614], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [154, 154, 614], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [154, 154, 614], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [154, 154, 614], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[307, 307, 1229], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [307, 307, 1229], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [307, 307, 1229], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [307, 307, 1229], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [307, 307, 1229], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [307, 307, 1229], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[614, 614, 2458], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [614, 614, 2458], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [614, 614, 2458], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D((2, 2), name=\"avg_pool\")(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(2458, activation='relu', name='fc_dense')(X)  # 2048 * 1.2 = 2458\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc_output')(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50_Scaled')\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model_ResNet50_scaled = ResNet50_Scaled(input_shape=(156, 156, 1), classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:37:27.706317Z",
     "iopub.status.busy": "2025-04-28T06:37:27.705929Z",
     "iopub.status.idle": "2025-04-28T06:37:27.715108Z",
     "shell.execute_reply": "2025-04-28T06:37:27.714454Z",
     "shell.execute_reply.started": "2025-04-28T06:37:27.706291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_ResNet50_scaled.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T06:37:33.967907Z",
     "iopub.status.busy": "2025-04-28T06:37:33.967315Z",
     "iopub.status.idle": "2025-04-28T07:55:08.495523Z",
     "shell.execute_reply": "2025-04-28T07:55:08.494944Z",
     "shell.execute_reply.started": "2025-04-28T06:37:33.967884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the path where the model with the best parameters will be saved\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# Create a callback that saves the model with the best validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',  # Save when val_accuracy is maximized\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback with patience=5\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=5,  # Stop training if no improvement after 10 epochs\n",
    "    mode='max',  # Check for maximization of val_accuracy\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint and early stopping callbacks\n",
    "history2 = model_ResNet50_scaled.fit(X_train_resized, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=50,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T07:55:08.497661Z",
     "iopub.status.busy": "2025-04-28T07:55:08.497036Z",
     "iopub.status.idle": "2025-04-28T07:55:08.830231Z",
     "shell.execute_reply": "2025-04-28T07:55:08.829533Z",
     "shell.execute_reply.started": "2025-04-28T07:55:08.497641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history1.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history1.history['val_accuracy'], label='Val Accuracy', linestyle='--')\n",
    "plt.title('ResNet-50 Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history1.history['loss'], label='Train Loss')\n",
    "plt.plot(history1.history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.title('ResNet-50 Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T07:55:08.831184Z",
     "iopub.status.busy": "2025-04-28T07:55:08.830954Z",
     "iopub.status.idle": "2025-04-28T07:55:09.142736Z",
     "shell.execute_reply": "2025-04-28T07:55:09.142119Z",
     "shell.execute_reply.started": "2025-04-28T07:55:08.831167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history2.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history2.history['val_accuracy'], label='Val Accuracy', linestyle='--')\n",
    "plt.title('ResNet-50 Scaled Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history2.history['loss'], label='Train Loss')\n",
    "plt.plot(history2.history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.title('ResNet-50 Scaled Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T07:55:09.144623Z",
     "iopub.status.busy": "2025-04-28T07:55:09.144391Z",
     "iopub.status.idle": "2025-04-28T07:55:09.533972Z",
     "shell.execute_reply": "2025-04-28T07:55:09.533447Z",
     "shell.execute_reply.started": "2025-04-28T07:55:09.144607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Function to calculate specificity and sensitivity for multi-class\n",
    "def specificity_score_multiclass(conf_matrix):\n",
    "    specificity_per_class = []\n",
    "    sensitivity_per_class = []\n",
    "    \n",
    "    for i in range(conf_matrix.shape[0]):  # Loop through each class\n",
    "        tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "        fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - conf_matrix[i, i]\n",
    "        tp = conf_matrix[i, i]\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        specificity_per_class.append(specificity)\n",
    "        sensitivity_per_class.append(sensitivity)\n",
    "    \n",
    "    return specificity_per_class, sensitivity_per_class\n",
    "\n",
    "# Function to print model metrics and confusion matrix\n",
    "def print_model_metrics(y_true, y_pred, model_name, class_names):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Compute specificity and sensitivity for each class\n",
    "    specificity, sensitivity = specificity_score_multiclass(conf_matrix)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nMetrics for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name}: Specificity: {specificity[i]:.4f}, Sensitivity: {sensitivity[i]:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Function to plot one image per class with predicted and true labels\n",
    "def plot_sample_images_per_class(X, y_true, y_pred, class_names):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    shown_classes = set()\n",
    "    class_indices = {}\n",
    "\n",
    "    # Find one index per class\n",
    "    for idx, label in enumerate(y_true):\n",
    "        if label not in shown_classes:\n",
    "            class_indices[label] = idx\n",
    "            shown_classes.add(label)\n",
    "        if len(shown_classes) == len(class_names):\n",
    "            break\n",
    "\n",
    "    for i, (label, idx) in enumerate(class_indices.items()):\n",
    "        image = X[idx]\n",
    "        if image.shape[-1] == 1:  # Grayscale\n",
    "            image = image.squeeze()\n",
    "        plt.subplot(1, len(class_names), i + 1)\n",
    "        plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"True: {class_names[y_true[idx]]}\\nPred: {class_names[y_pred[idx]]}\")\n",
    "\n",
    "    plt.suptitle(\"Sample Image Per Class with Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define your actual class names\n",
    "class_names = [\"Pituitary\", \"No Tumor\", \"Meningioma\", \"Glioma\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T07:59:47.446489Z",
     "iopub.status.busy": "2025-04-28T07:59:47.446232Z",
     "iopub.status.idle": "2025-04-28T08:00:05.479077Z",
     "shell.execute_reply": "2025-04-28T08:00:05.478370Z",
     "shell.execute_reply.started": "2025-04-28T07:59:47.446469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get predictions from your trained model\n",
    "y_pred1 = np.argmax(model_ResNet50.predict(X_test), axis=1)\n",
    "y_true1 = y_test  # Assuming it's label-encoded already\n",
    "\n",
    "# Show metrics and plots\n",
    "print_model_metrics(y_true1, y_pred1, 'ResNet-50', class_names)\n",
    "plot_sample_images_per_class(X_test, y_true1, y_pred1, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T07:58:46.139433Z",
     "iopub.status.busy": "2025-04-28T07:58:46.139160Z",
     "iopub.status.idle": "2025-04-28T07:59:15.927028Z",
     "shell.execute_reply": "2025-04-28T07:59:15.926244Z",
     "shell.execute_reply.started": "2025-04-28T07:58:46.139412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get predictions from your trained model\n",
    "y_pred1 = np.argmax(model_ResNet50_scaled.predict(X_test_resized), axis=1)\n",
    "y_true1 = y_test  # Assuming it's label-encoded already\n",
    "\n",
    "# Show metrics and plots\n",
    "print_model_metrics(y_true1, y_pred1, 'ResNet-50 Scaled', class_names)\n",
    "plot_sample_images_per_class(X_test_resized, y_true1, y_pred1, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3531266,
     "sourceId": 6568541,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
